{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc301e3f-e5e3-4596-8859-c0025b5a84b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.8.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Bunny/Documents/Praful sir/Mahindra_CNC/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load CNC Dataset\n",
    "cnc_data = pd.read_excel(\"C:\\\\Users\\\\Bunny\\\\Downloads\\\\CNC_Machine_Data_CNC003.xlsx\")\n",
    "cnc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e8d16-80d9-4cd3-af7d-98e9cec90a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cnc = cnc_data.dropna()\n",
    "dropped_cnc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddb605-153c-484f-9396-8377e610ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Dropping irrelevant columns\n",
    "cnc_data_cleaned = dropped_cnc.drop(['Timestamp', 'Machine ID', 'Production Line', 'Error Code'], axis=1)\n",
    "\n",
    "# Encoding categorical columns\n",
    "categorical_columns = cnc_data_cleaned.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    cnc_data_cleaned[col] = label_encoder.fit_transform(cnc_data_cleaned[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47534cd-3f30-48d7-b979-c792a1d5acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnc_data_cleaned.head()\n",
    "cnc_data_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cfa67-6e97-4856-9e35-580db9e551e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target\n",
    "X = cnc_data_cleaned.drop(['Maintenance Required'], axis=1)\n",
    "y = cnc_data_cleaned['Maintenance Required']\n",
    "\n",
    "# Splitting into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810596f-ad9a-42fb-9b39-c180a898ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to Evaluate\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LDA': LDA(),\n",
    "    'QDA': QDA()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c881b5-eb4f-4c90-9251-582554c1cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Each Model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb04da6-f444-4dca-9eba-087c219b5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying classification reports\n",
    "for name, report in results.items():\n",
    "    print(f\"\\n{name} Classification Report:\\n\")\n",
    "    print(classification_report(y_test, models[name].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a7c87-28e4-4c36-8c24-bd3cbab3c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "# Building a Sequential Model with an Input layer\n",
    "sequential_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Define input shape explicitly here\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "sequential_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5957d-fcd7-46d7-8ac6-2739bb96d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Sequential Model\n",
    "sequential_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate Sequential Model\n",
    "sequential_predictions = (sequential_model.predict(X_test) > 0.5).astype(int)\n",
    "print(\"\\nSequential Model Classification Report:\\n\")\n",
    "print(classification_report(y_test, sequential_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07475835-ddc5-4d45-b4ba-f5bf340b8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d8ed7-2680-46a2-8d00-727bdf30e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target\n",
    "X = cnc_data_cleaned.drop(['Maintenance Required'], axis=1)\n",
    "y = cnc_data_cleaned['Maintenance Required']\n",
    "\n",
    "# Splitting into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc008f-c6e2-4417-b798-77306e6f94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b341b-95f1-4d52-8b93-8c1347b6e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "optimized_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"\\nClassification Report for Optimized Decision Tree:\\n\")\n",
    "print(optimized_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87a30a-f6ee-4763-8941-572f4971b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_distributions = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480a972-190c-4e06-982d-57273462a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=dt_model,\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter=20,  # Number of random combinations to try\n",
    "                                   cv=5,  # Number of cross-validation folds\n",
    "                                   scoring='accuracy',\n",
    "                                   verbose=1,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and estimator\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf3d65-417d-43c4-b738-e76bfe524914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model\n",
    "y_pred = best_model.predict(X_test)\n",
    "optimized_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"\\nClassification Report for Optimized Decision Tree:\\n\")\n",
    "print(optimized_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cca435-8e3f-4cfc-ad93-751b528d0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize variables to store the best parameters and score\n",
    "best_params = None\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9266fe4-2b2d-466a-8262-372c8ef95ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.values if hasattr(y_train, \"values\") else y_train\n",
    "\n",
    "# Perform Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for max_depth in param_grid['max_depth']:\n",
    "    for min_samples_split in param_grid['min_samples_split']:\n",
    "        for min_samples_leaf in param_grid['min_samples_leaf']:\n",
    "            fold_scores = []\n",
    "\n",
    "            for train_idx, val_idx in kf.split(X_train, y_train_array):\n",
    "                # Split the data into train and validation sets\n",
    "                X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "                y_fold_train, y_fold_val = y_train_array[train_idx], y_train_array[val_idx]\n",
    "\n",
    "                # Initialize the model with the current set of parameters\n",
    "                model = DecisionTreeClassifier(\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=min_samples_split,\n",
    "                    min_samples_leaf=min_samples_leaf,\n",
    "                    random_state=42\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1777a4d-89bc-4a3e-bdbd-481417e3b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "# Validate the model\n",
    "y_pred = model.predict(X_fold_val)\n",
    "fold_scores.append(accuracy_score(y_fold_val, y_pred))\n",
    "\n",
    "# Calculate the average score across folds\n",
    "avg_score = np.mean(fold_scores)\n",
    "\n",
    "# Update the best parameters if the current score is better\n",
    "if avg_score > best_score:\n",
    " best_score = avg_score\n",
    "best_params = {\n",
    "'max_depth': max_depth,\n",
    "'min_samples_split': min_samples_split,\n",
    "'min_samples_leaf': min_samples_leaf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ccf0d3-6f29-48dc-b43f-5d590c4b3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best parameters on the full training data\n",
    "final_model = DecisionTreeClassifier(\n",
    "    **best_params, random_state=42\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "final_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Display the results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validated Accuracy:\", best_score)\n",
    "print(\"\\nClassification Report for Final Model:\\n\")\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7db06-814e-4f57-9a78-63d94a2f8a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf5589-d08f-4d81-aff4-3590533f4511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63266938-beea-4ea7-84a0-a7b092a7124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train and X_test to DataFrames with column names\n",
    "X_train_df = pd.DataFrame(X_train, columns=cnc_data_cleaned.drop(\"Maintenance Required\", axis=1).columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=cnc_data_cleaned.drop(\"Maintenance Required\", axis=1).columns)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = X_train_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Remove highly correlated features\n",
    "threshold = 0.9  # Correlation threshold\n",
    "correlated_features = set()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            correlated_features.add(correlation_matrix.columns[i])\n",
    "\n",
    "# Drop correlated features\n",
    "X_train_uncorrelated = X_train_df.drop(columns=correlated_features)\n",
    "X_test_uncorrelated = X_test_df.drop(columns=correlated_features)\n",
    "\n",
    "# Print the features retained after removing highly correlated features\n",
    "print(\"Features retained after correlation analysis:\", X_train_uncorrelated.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f1db8-6a2d-4b52-ac42-d3e9dd30a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.Series(rf_model.feature_importances_, index=X_train_df.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importances.sort_values(ascending=False).plot(kind='bar')\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()\n",
    "\n",
    "# Select top features based on importance\n",
    "top_features = feature_importances.nlargest(10).index  # Select top 10 features\n",
    "X_train_important = X_train_df[top_features]\n",
    "X_test_important = X_test_df[top_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b67da-112d-45f4-869d-f2ef3dc34566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Calculate mutual information scores\n",
    "mi_scores = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "# Convert scores to a Series with column names\n",
    "mi_scores_series = pd.Series(mi_scores, index=X_train_df.columns)\n",
    "\n",
    "# Plot mutual information scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "mi_scores_series.sort_values(ascending=False).plot(kind='bar')\n",
    "plt.title(\"Mutual Information Scores\")\n",
    "plt.ylabel(\"Mutual Information\")\n",
    "plt.show()\n",
    "\n",
    "# Select features with high mutual information\n",
    "threshold = 0.01  # Minimum score to keep a feature\n",
    "selected_features = mi_scores_series[mi_scores_series > threshold].index\n",
    "X_train_selected = X_train_df[selected_features]\n",
    "X_test_selected = X_test_df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda2d58-a0a0-42eb-ac26-8c9df2b99974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize a Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform RFE\n",
    "rfe = RFE(estimator=dt_model, n_features_to_select=10)\n",
    "rfe.fit(X_train_df, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X_train_df.columns[rfe.support_]\n",
    "\n",
    "# Transform the dataset\n",
    "X_train_rfe = X_train_df[selected_features]\n",
    "X_test_rfe = X_test_df[selected_features]\n",
    "\n",
    "print(\"Selected Features:\", selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7462065-deca-4ffe-8f10-1837da6795c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable\n",
    "target_distribution = cnc_data_cleaned['Maintenance Required'].value_counts()\n",
    "print(\"Target Variable Distribution:\\n\", target_distribution)\n",
    "\n",
    "# Percentage distribution\n",
    "target_percentage = cnc_data_cleaned['Maintenance Required'].value_counts(normalize=True) * 100\n",
    "print(\"\\nTarget Variable Percentage Distribution:\\n\", target_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b680c1a-a029-4a95-9944-a0b71d029fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize features for each target class\n",
    "summary = cnc_data_cleaned.groupby('Maintenance Required').mean()\n",
    "print(\"\\nMean Feature Values by Target Class:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae80ed-e7c4-4816-a563-af5384263a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
